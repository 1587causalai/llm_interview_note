# 1.基础

1.  目前 主流的开源模型体系 有哪些？
2.  prefix Decoder 和 causal Decoder 和 Encoder-Decoder 区别是什么？
3.  大模型LLM的 训练目标 是什么？
4.  涌现能力是啥原因？
5.  为何现在的大模型大部分是Decoder only结构？
6.  简单 介绍一下 大模型【LLMs】？

#### 1.目前 主流的开源模型体系 有哪些？

目前主流的开源LLM（语言模型）模型体系包括以下几个：

1.  **GPT（Generative Pre-trained Transformer）系列**：由OpenAI发布的一系列基于Transformer架构的语言模型，包括GPT、GPT-2、GPT-3等。GPT模型通过在大规模无标签文本上进行预训练，然后在特定任务上进行微调，具有很强的生成能力和语言理解能力。
2.  **BERT（Bidirectional Encoder Representations from Transformers）**：由Google发布的一种基于Transformer架构的双向预训练语言模型。BERT模型通过在大规模无标签文本上进行预训练，然后在下游任务上进行微调，具有强大的语言理解能力和表征能力。
3.  **XLNet**：由CMU和Google Brain发布的一种基于Transformer架构的自回归预训练语言模型。XLNet模型通过自回归方式预训练，可以建模全局依赖关系，具有更好的语言建模能力和生成能力。
4.  **RoBERTa**：由Facebook发布的一种基于Transformer架构的预训练语言模型。RoBERTa模型在BERT的基础上进行了改进，通过更大规模的数据和更长的训练时间，取得了更好的性能。
5.  **T5（Text-to-Text Transfer Transformer）**：由Google发布的一种基于Transformer架构的多任务预训练语言模型。T5模型通过在大规模数据集上进行预训练，可以用于多种自然语言处理任务，如文本分类、机器翻译、问答等。

这些模型在自然语言处理领域取得了显著的成果，并被广泛应用于各种任务和应用中。

#### 2.prefix LM 和 causal LM 区别是什么？

Prefix LM（前缀语言模型）和Causal LM（因果语言模型）是两种不同类型的语言模型，它们的区别在于生成文本的方式和训练目标。

1.  **Prefix LM**：前缀语言模型是一种生成模型，它在生成每个词时都可以考虑之前的上下文信息。在生成时，前缀语言模型会根据给定的前缀（即部分文本序列）预测下一个可能的词。这种模型可以用于文本生成、机器翻译等任务。
2.  **Causal LM**：因果语言模型是一种自回归模型，它只能根据之前的文本生成后续的文本，而不能根据后续的文本生成之前的文本。在训练时，因果语言模型的目标是预测下一个词的概率，给定之前的所有词作为上下文。这种模型可以用于文本生成、语言建模等任务。

总结来说，前缀语言模型可以根据给定的前缀生成后续的文本，而因果语言模型只能根据之前的文本生成后续的文本。它们的训练目标和生成方式略有不同，适用于不同的任务和应用场景。

#### 3.大模型LLM的 训练目标

大型语言模型（Large Language Models，LLM）的训练目标通常是**最大似然估计（Maximum Likelihood Estimation，MLE）**。最大似然估计是一种统计方法，用于从给定数据中估计概率模型的参数。

在LLM的训练过程中，使用的数据通常是大量的文本语料库。训练目标是**最大化模型生成训练数据中观察到的文本序列的概率**。具体来说，对于每个文本序列，模型根据前面的上下文生成下一个词的条件概率分布，并通过最大化生成的词序列的概率来优化模型参数。

为了最大化似然函数，可以使用梯度下降等优化算法来更新模型参数，使得模型生成的文本序列的概率逐步提高。在训练过程中，通常会使用批量训练（batch training）的方法，通过每次处理一小批数据样本来进行参数更新。

#### 4.涌现能力是啥原因？

[大语言模型的涌现能力：现象与解释 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/621438653 "大语言模型的涌现能力：现象与解释 - 知乎 (zhihu.com)")

涌现能力（Emergent Ability）是指**模型在训练过程中能够生成出令人惊喜、创造性和新颖的内容或行为**。这种能力使得模型能够超出其训练数据所提供的内容，并产生出具有创造性和独特性的输出。

涌现能力的产生可以归因于以下几个原因：

1.  **任务的评价指标不够平滑**：因为很多任务的评价指标不够平滑，导致我们现在看到的涌现现象。如果评价指标要求很严格，要求一字不错才算对，那么Emoji\_movie任务我们就会看到涌现现象的出现。但是，如果我们把问题形式换成多选题，就是给出几个候选答案，让LLM选，那么随着模型不断增大，任务效果在持续稳定变好，但涌现现象消失，如上图图右所示。这说明评价指标不够平滑，起码是一部分任务看到涌现现象的原因。
2.  **复杂任务** **vs** **子任务**：展现出涌现现象的任务有一个共性，就是任务往往是由多个子任务构成的复杂任务。也就是说，最终任务过于复杂，如果仔细分析，可以看出它由多个子任务构成，这时候，子任务效果往往随着模型增大，符合 Scaling Law，而最终任务则体现为涌现现象。
3.  **用** **Grokking** （顿悟）**来解释涌现**：对于某个任务T，尽管我们看到的预训练数据总量是巨大的，但是与T相关的训练数据其实数量很少。当我们推大模型规模的时候，往往会伴随着增加预训练数据的数据量操作，这样，当模型规模达到某个点的时候，与任务T相关的数据量，突然就达到了最小要求临界点，于是我们就看到了这个任务产生了Grokking现象。

尽管涌现能力为模型带来了创造性和独特性，但也需要注意其生成的内容可能存在偏差、错误或不完整性。因此，在应用和使用涌现能力强的模型时，需要谨慎评估和验证生成的输出，以确保其质量和准确性。

#### 5.为何现在的大模型大部分是Decoder only结构

1.  **自回归生成**：Decoder-only结构适用于自回归生成任务，其中模型根据先前的输入生成下一个输出。这种结构在自然语言处理任务中非常有用，如文本生成、机器翻译和对话生成等。**Decoder-only结构能够利用上下文信息来生成连续的输出序列，使得生成的结果更加准确和连贯**。
2.  **生成多样性**：Decoder-only结构可以通过在训练期间使用不同的解码策略来生成多样化的结果。例如，在生成文本时，可以使用不同的采样策略（如贪婪采样或随机采样）或温度参数来调整生成的多样性。这种能力对于一些任务（如对话生成）非常重要，因为它可以产生更加有趣和多样化的回复。
3.  **模型训练和推理的一致性**：Decoder-only结构使得模型的训练和推理过程更加一致。在训练期间，模型可以使用教师强制（teacher forcing）策略，即将真实的目标输出作为输入传递给解码器。而在推理期间，模型可以逐步生成输出，将前一个时间步的输出作为输入传递给下一个时间步。这种一致性有助于更好地控制模型的生成过程，并提高模型的稳定性和可靠性。

#### 6.大模型架构介绍

LLM（Large Language Model，大型语言模型）是指基于大规模数据和参数量的语言模型。具体的架构可以有多种选择，以下是一种常见的大模型LLM的架构介绍：

1.  **Transformer架构**：大模型LLM常使用Transformer架构，它是一种基于自注意力机制的序列模型。Transformer架构由多个编码器层和解码器层组成，每个层都包含多头自注意力机制和前馈神经网络。这种架构可以捕捉长距离的依赖关系和语言结构，适用于处理大规模语言数据。
2.  **自注意力机制（Self-Attention）**：自注意力机制是Transformer架构的核心组件之一。它允许模型在生成每个词时，根据输入序列中的其他词来计算该词的表示。自注意力机制能够动态地为每个词分配不同的权重，从而更好地捕捉上下文信息。
3.  **多头注意力（Multi-Head Attention）**：多头注意力是自注意力机制的一种扩展形式。它将自注意力机制应用多次，每次使用不同的权重矩阵进行计算，得到多个注意力头。多头注意力可以提供更丰富的上下文表示，增强模型的表达能力。
4.  **前馈神经网络（Feed-Forward Network）**：在Transformer架构中，每个注意力层后面都有一个前馈神经网络。前馈神经网络由两个全连接层组成，通过非线性激活函数（如ReLU）进行变换。它可以对注意力层输出的表示进行进一步的映射和调整。
5.  **预训练和微调**：大模型LLM通常采用预训练和微调的方法进行训练。预训练阶段使用大规模无标签数据，通过自监督学习等方法进行训练，使模型学习到丰富的语言知识。微调阶段使用有标签的特定任务数据，如文本生成、机器翻译等，通过有监督学习进行模型的微调和优化。

需要注意的是，大模型LLM的具体架构可能会因不同的研究和应用而有所不同。上述介绍的是一种常见的架构，但实际应用中可能会有一些变体或改进。
