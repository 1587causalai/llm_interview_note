# 13.分布式训练

-   1\.  理论篇
    -   1.1 训练 大语言模型 存在问题？
    -   1.2 什么是 点对点通信？
    -   1.3 什么是 集体通信？
    -   1.4 什么是 数据并行？
    -   1.5 数据并行 如何 提升效率？
    -   1.6 什么是 流水线并行？
    -   1.7 什么是 张量并行 (intra-layer)？
    -   1.8 数据并行 vs 张量并行 vs 流水线并行?
    -   1.9 什么是 3D并行？
    -   1.10 想要训练1个LLM，如果只想用1张显卡，那么对显卡的要求是什么？
    -   1.11 如果有N张显存足够大的显卡，怎么加速训练？
    -   1.12 如果显卡的显存不够装下一个完整的模型呢？
    -   1.13 PP推理时，是一个串行的过程，1个GPU计算，其他空闲，有没有其他方式？
    -   1.14 3种并行方式可以叠加吗？
    -   1.15 Colossal-AI 有1D/2D/2.5D/3D，是什么情况？
    -   1.16 除了3D并行有没有其他方式大规模训练？
    -   1.17 有了ZeRO系列，为什么还需要3D并行？
    -   1.18 平民适不适合玩3D并行？
    -   1.19 平民适不适合直接上多机多卡的ZeRO3（万兆网）？
    -   1.20 分布式并行及显存优化技术并行技术有哪一些，都有什么特点？
    -   1.21 显存优化技术有哪一些，都有什么特点？
    -   1.22 常见的分布式训练框架哪一些，都有什么特点？
-   2\.  实践篇
    -   2.1 假如有超多的8卡A100节点（DGX A100），如何应用3D并行策略？
    -   2.2 如果想构这样一个大规模并行训练系统，训练框架如何选？
    -   2.3 训练框架如何选？
-   3\.  并行化策略选择篇
    -   3.1 如何选择一款分布式训练框架？
    -   3.2 如何选择一款分布式训练框架？
    -   3.3 单GPU
    -   3.4 单节点多卡
    -   3.5 多节点多卡
-   4\.  问题篇
    -   4.1 推理速度验证
    -   4.2 并行化训练加速
    -   4.3 deepspeed 训练过程，报找不主机
    -   4.4 为什么 多机训练效率不如单机？
    -   4.5 多机训练不通，DeepSPeed配置问题
