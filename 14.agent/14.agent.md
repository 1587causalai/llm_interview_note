[TOC]



### 1.什么是 LLM Agent?

LLM Agent 是一种人工智能系统，它**利用大型语言模型 (LLM) 作为其核心计算引擎**，展示文本生成之外的功能，包括进行对话、完成任务、推理，并可以展示一定程度的**自主行为**。

LLM Agent 根据设计阶段授予的功能，Agent 从纯粹的被动到高度主动的自主行为。同时利用大模型的推理能力，让 Agent 可以在人工监督下管理相对独立的工作流程：分析目标，项目规划，执行，回顾过去的工作，迭代细化。

### 2. LLM Agent 有什么关键能力？

1. Agent利用LLM的语言能力理解指令、上下文和目标。可以根据人类提示**自主和半自主操作**。
2. 可以**利用工具套件**（计算器、API、搜索引擎）来收集信息并采取行动来完成分配的任务。它们不仅仅局限于语言处理。
3. 可以做**逻辑推理**类型的任务。例如，chain-of-thought , tree-of-thought。
4. 可以量身**定制文本**，例如邮件，报告，市场材料。
5. 可以自动或半自动的**响应用户的需求**。
6. Agent可以和不同类型的AI系统对接，例如LLM+image generators。

### 3. 怎样构建基于 LLM 的 Agents？

```
Agent = LLM + Prompt Recipe + Tools + Interface + Knowledge + Memory
```

1. Prompt Recipe：特定的内容要求、目标受众、所需的语气、输出长度、创造力水平等。
2. Tools：工具集成允许通过API和外部服务完成任务。Agents 能够理解自然语言、推理提示、积累记忆并采取明智的行动。但是，Agents 的表现和一致性取决于他们收到的提示的质量。
3. Knowledge：知识适用于所有用户的一般专业知识。知识扩展了LLM的内容。一般分为专业知识、常识知识和程序知识。
4. Memory：单个用户或单个任务的上下文和记录细节。分为短期记忆和长期记忆。记忆服务与特定用户，在时间维度的体验。使特定用户的上下文对话个性化同时保持多步骤任务的一致性。记忆侧重暂时的用户和任务细节。

### 4. LLM Agents 有哪些类型？

一般来说 LLM Agents 分为**会话型 Agents 和任务型 Agents**，两者在目标、行为和prompt方法都有重要区别。 会话型专注于提供引人入胜的个性化讨论，任务型致力于完成明确定义的目标。

**Conversational Agents**：模拟人类对话，能够在讨论中反映人类的倾向。允许细致入微的上下文交互，会考虑语气、说话风格、领域知识、观点和个性怪癖等因素。agent的开发者可以持续增强记忆、知识整合提高响应能力，持续优化应用。

**Task-Oriented Agents**：实现目标驱动，利用模型的能力分析prompt、提取关键参数、指定计划、调用API、通过集成tools执行操作，并生成结果回复。Prompt 工程把目标型Agents拆分成如下环节：制定战略任务、串联思路、反思过去的工作以及迭代改进的方法。

### 5. 是什么让Agent有了自制的能力？

通常有自制能力的系统，至少有两类agent组成。**一个用于生成的agent，一个用于监督的agent**。生成agent根据提示生成回复。监督agent在必要时审查和重新提示或指示生成agent继续工作，同时提供交互反馈。自主技能是通过持续提示培养出来的。专门的监督agent提供方向、纠正和不断提高挑战，持续的提示释放了推理、效能和自主决策能力的增长。

### 6.如何给LLM注入领域知识？

给LLM（低层次模型，如BERT、GPT等）注入领域知识的方法有很多。以下是一些建议：

1. 数据增强：在训练过程中，可以通过添加领域相关的数据来增强模型的训练数据。这可以包括从领域相关的文本中提取示例、对现有数据进行扩充或生成新的数据。
2. 迁移学习：使用预训练的LLM模型作为基础，然后在特定领域的数据上进行微调。这样可以利用预训练模型学到的通用知识，同时使其适应新领域。
3. 领域专家标注：与领域专家合作，对模型的输出进行监督式标注。这可以帮助模型学习到更准确的领域知识。
4. 知识图谱：将领域知识表示为知识图谱，然后让LLM模型通过学习知识图谱中的实体和关系来理解领域知识。
5. 规则和启发式方法：编写领域特定的规则和启发式方法，以指导模型的学习过程。这些方法可以是基于规则的、基于案例的或基于实例的。
6. 模型融合：将多个LLM模型的预测结果结合起来，以提高模型在特定领域的性能。这可以通过投票、加权平均或其他集成方法来实现。
7. 元学习：训练一个元模型，使其能够在少量领域特定数据上快速适应新领域。这可以通过在线学习、模型蒸馏或其他元学习方法来实现。
8. 模型解释性：使用模型解释工具（如LIME、SHAP等）来理解模型在特定领域的预测原因，从而发现潜在的知识缺失并加以补充。
9. 持续学习：在模型部署后，持续收集领域特定数据并更新模型，以保持其在新数据上的性能。
10. 多任务学习：通过同时训练模型在多个相关任务上的表现，可以提高模型在特定领域的泛化能力。